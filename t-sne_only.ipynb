{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T-SNE stuff only - cleaned up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install seaborn\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "for i in range(10):\n",
    "    clear_output(wait=True)\n",
    "    print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# One hot encoding categorical feature\n",
    "def one_hot_enc(df,col_name):\n",
    "    df = df.reset_index(drop=True)\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    encoder_df = pd.DataFrame(encoder.fit_transform(df[[col_name]]).toarray())\n",
    "    df = df.drop(col_name, axis=1)\n",
    "    df_final = df.join(encoder_df)\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting(df):\n",
    "    df['mult'] = (df['Feature 1']) * (df['Feature 2'])\n",
    "    # plotting needs changes\n",
    "    plt.scatter(df['Feature 1'],df['Feature 2'], c= df['mult'])\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.show()\n",
    "    df = df.drop('mult', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "def find_eps(df):\n",
    "    neigh = NearestNeighbors(n_neighbors=2)\n",
    "    nbrs = neigh.fit(df)\n",
    "    distances, indices = nbrs.kneighbors(df)\n",
    "    distances = np.sort(distances, axis=0)\n",
    "    distances = distances[:,1]\n",
    "    plt.plot(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(df, mode='dbscan', eps=10):\n",
    "    # Create and plot clusters\n",
    "    # Number of centroids\n",
    "    # Optimal number of clusters is 22, according to the Elbow method\n",
    "    if mode == 'km':\n",
    "        K = 12\n",
    "        # Select random observation as a centroid\n",
    "        km = KMeans(n_clusters=K, init='random', n_init=10, max_iter=300, tol=1e-02, random_state=0)\n",
    "        prediction = km.fit_predict(df)\n",
    "        df['cluster'] = km.labels_\n",
    "    else:\n",
    "        clustering = DBSCAN(eps=eps, min_samples=10).fit(df)\n",
    "        df['cluster'] = clustering.labels_\n",
    "    return df\n",
    "\n",
    "def clustering_plot(df):\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    sns.scatterplot(\n",
    "        x='Feature 1', y='Feature 2',\n",
    "        hue='cluster',\n",
    "        palette='gist_rainbow',\n",
    "        # style='name',\n",
    "        legend='full',\n",
    "        data=df\n",
    "    )\n",
    "    plt.legend(bbox_to_anchor=(1.25, 1), loc='upper right', borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16269\n",
      "16268\n"
     ]
    }
   ],
   "source": [
    "#Reading the music data from CSV\n",
    "\n",
    "df = pd.read_csv(\"data/dataset.csv\")\n",
    "print(len(df))\n",
    "df = df.dropna()\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.695</td>\n",
       "      <td>0.541</td>\n",
       "      <td>2</td>\n",
       "      <td>-8.350</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.00707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.409</td>\n",
       "      <td>140.018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.573</td>\n",
       "      <td>0.507</td>\n",
       "      <td>11</td>\n",
       "      <td>-8.084</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.75900</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.3770</td>\n",
       "      <td>0.363</td>\n",
       "      <td>123.183</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.594</td>\n",
       "      <td>0.640</td>\n",
       "      <td>10</td>\n",
       "      <td>-6.865</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.01690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>0.492</td>\n",
       "      <td>92.871</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.704</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.927</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.08260</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.0546</td>\n",
       "      <td>0.825</td>\n",
       "      <td>139.994</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.742</td>\n",
       "      <td>0.527</td>\n",
       "      <td>8</td>\n",
       "      <td>-6.892</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.32700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.638</td>\n",
       "      <td>84.974</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability  energy  key  loudness  mode  speechiness  acousticness  \\\n",
       "0         0.695   0.541    2    -8.350     1       0.0460       0.00707   \n",
       "1         0.573   0.507   11    -8.084     1       0.0342       0.75900   \n",
       "2         0.594   0.640   10    -6.865     1       0.0330       0.01690   \n",
       "3         0.704   0.797    0    -5.927     1       0.0475       0.08260   \n",
       "4         0.742   0.527    8    -6.892     0       0.0769       0.32700   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo  time_signature  \n",
       "0          0.000000    0.1040    0.409  140.018               4  \n",
       "1          0.000001    0.3770    0.363  123.183               4  \n",
       "2          0.000000    0.1350    0.492   92.871               4  \n",
       "3          0.000745    0.0546    0.825  139.994               4  \n",
       "4          0.000000    0.2500    0.638   84.974               4  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature Selection\n",
    "\n",
    "columns_to_select = [\n",
    "    # \"id_x\",             # Track id\n",
    "    # \"track.artists\",\n",
    "    # \"track.name\",\n",
    "    # \"playlist_id\",\n",
    "    # \"name\",             # Playlist name\n",
    "    # \"track.popularity\"\n",
    "    # \"duration_ms\",\n",
    "    \"danceability\",\n",
    "    \"energy\",\n",
    "    \"key\",\n",
    "    \"loudness\",\n",
    "    \"mode\",\n",
    "    \"speechiness\",\n",
    "    \"acousticness\",\n",
    "    \"instrumentalness\",\n",
    "    \"liveness\",\n",
    "    \"valence\",\n",
    "    \"tempo\",\n",
    "    \"time_signature\"\n",
    "]\n",
    "\n",
    "# Filter the playlists if needed and drop duplicates\n",
    "# df_filtered = df[df['name'].isin(playlists_to_select)]\n",
    "df_filtered = df.drop_duplicates(subset=['id_x'])\n",
    "df_filtered = df_filtered[columns_to_select]\n",
    "df_filtered = df_filtered.reset_index(drop=True)\n",
    "\n",
    "df_filtered.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_filtered\n",
    "# X_enc = one_hot_enc(df_filtered,'key')\n",
    "X_no_key = X.drop('key', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 151 nearest neighbors...\n",
      "[t-SNE] Indexed 14538 samples in 0.004s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:800: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:810: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computed neighbors for 14538 samples in 0.374s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 5000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 6000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 7000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 8000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 9000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 10000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 11000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 12000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 13000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 14000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 14538 / 14538\n",
      "[t-SNE] Mean sigma: 1.772138\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 72.476013\n",
      "[t-SNE] KL divergence after 1000 iterations: 1.181893\n",
      "[t-SNE] Computing 151 nearest neighbors...\n",
      "[t-SNE] Indexed 14538 samples in 0.004s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:800: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:810: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computed neighbors for 14538 samples in 2.246s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 5000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 6000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 7000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 8000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 9000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 10000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 11000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 12000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 13000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 14000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 14538 / 14538\n",
      "[t-SNE] Mean sigma: 0.685159\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 80.266724\n",
      "[t-SNE] KL divergence after 1000 iterations: 1.596757\n",
      "[t-SNE] Computing 151 nearest neighbors...\n",
      "[t-SNE] Indexed 14538 samples in 0.003s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:800: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:810: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computed neighbors for 14538 samples in 0.282s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 5000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 6000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 7000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 8000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 9000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 10000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 11000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 12000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 13000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 14000 / 14538\n",
      "[t-SNE] Computed conditional probabilities for sample 14538 / 14538\n",
      "[t-SNE] Mean sigma: 1.135619\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 68.521858\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# t-SNE\n",
    "\n",
    "# Examples:\n",
    "# https://towardsdatascience.com/visualising-high-dimensional-datasets-using-pca-and-t-sne-in-python-8ef87e7915b\n",
    "\n",
    "# Scale/normalize values\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Not encoded key, normalized\n",
    "X_norm = scaler.fit_transform(X)\n",
    "\n",
    "# Encoded key, rescalled\n",
    "# X_enc_norm = scaler.fit_transform(X_enc)\n",
    "\n",
    "# No key, normalized\n",
    "X_no_key_norm = scaler.fit_transform(X_no_key)\n",
    "\n",
    "# Perform t-SNE to 2 dimensions\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=50, n_iter=1000)\n",
    "\n",
    "# Not encoded, not normalized\n",
    "tsne_results = tsne.fit_transform(X);\n",
    "\n",
    "# Not encoded, normalized\n",
    "tsne_results_norm = tsne.fit_transform(X_norm);\n",
    "\n",
    "# Encoded, not normalized\n",
    "# tsne_results_enc= tsne.fit_transform(X_enc);\n",
    "\n",
    "# Encoded, normalized\n",
    "# tsne_results_enc_norm= tsne.fit_transform(c);\n",
    "\n",
    "# No key, not rescalled\n",
    "tsne_results_no_key= tsne.fit_transform(X_no_key);\n",
    "\n",
    "# No key, rescalled\n",
    "tsne_results_no_key_norm= tsne.fit_transform(X_no_key_norm);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting\n",
    "lower_dim = pd.DataFrame(tsne_results, columns=['Feature 1', 'Feature 2'])\n",
    "lower_dim_norm = pd.DataFrame(tsne_results_norm, columns=['Feature 1', 'Feature 2'])\n",
    "# lower_dim_enc = pd.DataFrame(tsne_results_enc, columns=['Feature 1', 'Feature 2'])\n",
    "# lower_dim_enc_norm = pd.DataFrame(tsne_results_enc_norm, columns=['Feature 1', 'Feature 2'])\n",
    "\n",
    "lower_dim_no_key = pd.DataFrame(tsne_results_no_key, columns=['Feature 1', 'Feature 2'])\n",
    "\n",
    "lower_dim_no_key_norm = pd.DataFrame(tsne_results_no_key_norm, columns=['Feature 1', 'Feature 2'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot for not encoded, not rescaled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting(lower_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot for not encoded, rescaled dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting(lower_dim_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot for encoded, not rescaled dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting(lower_dim_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot for encoded, rescaled dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting(lower_dim_enc_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot for no key, not rescaled dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting(lower_dim_no_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot for no key, rescaled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting(lower_dim_no_key_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality Measurement, Metric : Trustworthiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run trustworthiness\n",
    "from sklearn.manifold import trustworthiness as trustworthiness\n",
    "score = trustworthiness(lower_dim,X,n_neighbors=5, metric='euclidean')\n",
    "score_norm = trustworthiness(lower_dim_norm,X_norm,n_neighbors=5, metric='euclidean')\n",
    "# score_enc = trustworthiness(lower_dim_enc,X_enc,n_neighbors=5, metric='euclidean')\n",
    "# score_enc_norm = trustworthiness(lower_dim_enc_norm,X_enc_norm,n_neighbors=5, metric='euclidean')\n",
    "score_no_key = trustworthiness(lower_dim_no_key,X_no_key,n_neighbors=5, metric='euclidean')\n",
    "score_no_key_norm = trustworthiness(lower_dim_no_key_norm,X_no_key_norm,n_neighbors=5, metric='euclidean')\n",
    "\n",
    "print(f'Trustworthiness for not encoded, not normalized is :{score}')\n",
    "print(f'Trustworthiness for not encoded, normalized is :{score_norm}')\n",
    "# print(f'Trustworthiness for encoded, not normalized is :{score_enc}')\n",
    "# print(f'Trustworthiness for encoded, normalized is :{score_enc_norm}')\n",
    "print(f'Trustworthiness for no key, not normalized is :{score_no_key}')\n",
    "print(f'Trustworthiness for no key, normalized is :{score_no_key_norm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_eps(lower_dim_no_key_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_no_key_norm = clustering(lower_dim_no_key_norm,eps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = cluster_no_key_norm.join(X['key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster and key correlation is very high. It's better if we drop the key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "sns.scatterplot(\n",
    "    x='Feature 1', y='Feature 2',\n",
    "    hue='cluster',\n",
    "    palette='gist_rainbow',\n",
    "    # style='name',\n",
    "    legend='full',\n",
    "    data=cluster_no_key_norm\n",
    "    )\n",
    "plt.legend(bbox_to_anchor=(1.25, 1), loc='upper right', borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
